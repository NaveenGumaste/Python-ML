{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\kle_tech\\be\\programs\\python ml\\.venv\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\kle_tech\\be\\programs\\python ml\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     ---- ----------------------------------- 41.0/341.8 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 122.9/341.8 kB 1.4 MB/s eta 0:00:01\n",
      "     --------------------- ---------------- 194.6/341.8 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 341.8/341.8 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in d:\\kle_tech\\be\\programs\\python ml\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.3-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.6 MB 5.9 MB/s eta 0:00:02\n",
      "    --------------------------------------- 0.3/10.6 MB 2.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.3/10.6 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/10.6 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/10.6 MB 2.3 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.5/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/10.6 MB 1.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/10.6 MB 1.8 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/10.6 MB 1.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.7/10.6 MB 1.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.7/10.6 MB 1.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.8/10.6 MB 1.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.0/10.6 MB 1.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.1/10.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.4/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.7/10.6 MB 1.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.8/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.9/10.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.0/10.6 MB 1.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.2/10.6 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.3/10.6 MB 1.7 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.4/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.6/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.6/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.7/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.7/10.6 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.9/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.4/10.6 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.5/10.6 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.7/10.6 MB 2.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.9/10.6 MB 2.0 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.0/10.6 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 2.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.5/10.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.9/10.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.0/10.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.6 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.5/10.6 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.7/10.6 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 5.8/10.6 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.1/10.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.8/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.8/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.9/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.4/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.4/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.6/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.7/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.2/10.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/10.6 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.8/10.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.8/10.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 378.9/502.5 kB 8.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 502.5/502.5 kB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.1.3 pytz-2023.3.post1 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Kle_Tech\\BE\\Programs\\Python ML\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Kle_Tech\\BE\\Programs\\Python ML\\Eye Code.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kle_Tech/BE/Programs/Python%20ML/Eye%20Code.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m layers, models\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kle_Tech/BE/Programs/Python%20ML/Eye%20Code.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapplications\u001b[39;00m \u001b[39mimport\u001b[39;00m DenseNet121\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Kle_Tech/BE/Programs/Python%20ML/Eye%20Code.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kle_Tech/BE/Programs/Python%20ML/Eye%20Code.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Define your dataset path\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Kle_Tech/BE/Programs/Python%20ML/Eye%20Code.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,/Kle_Tech/BE/Programs/Python ML/train\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your dataset path\n",
    "dataset_path = ',/Kle_Tech/BE/Programs/Python ML/train'\n",
    "\n",
    "# List all image files in the dataset path\n",
    "image_files = [os.path.join(dataset_path, file) for file in os.listdir(\n",
    "    dataset_path) if file.endswith('.jpg')]\n",
    "\n",
    "# Assuming a binary classification (e.g., healthy vs. diseased eyes)\n",
    "labels = [0 if 'healthy' in file else 1 for file in image_files]\n",
    "\n",
    "# Calculate a reasonable test size based on the size of your dataset\n",
    "dataset_size = len(image_files)\n",
    "\n",
    "# Adjust test size to ensure there's enough data for training\n",
    "test_size = min(0.2, dataset_size - 1) if dataset_size > 1 else 0.2\n",
    "\n",
    "# If the dataset size is very small, set a default test size\n",
    "if dataset_size <= 1:\n",
    "    test_size = 0.1\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    image_files, labels, test_size=test_size, random_state=42)\n",
    "\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess(file_path, label):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Assuming RGB images\n",
    "    # Resize images to a consistent size\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = img / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "    return img, label\n",
    "\n",
    "\n",
    "# Create TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_files, train_labels))\n",
    "train_dataset = train_dataset.map(load_and_preprocess)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_files, test_labels))\n",
    "test_dataset = test_dataset.map(load_and_preprocess)\n",
    "\n",
    "# Shuffle and batch the datasets\n",
    "batch_size = 32\n",
    "train_dataset = train_dataset.shuffle(\n",
    "    buffer_size=len(train_files)).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "# Load the pre-trained DenseNet121 model\n",
    "base_model = DenseNet121(\n",
    "    include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    # Binary classification, so using sigmoid activation\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save the model\n",
    "model.save('eye_disease_detection.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
